{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Практическая работа № 6\n",
        "\n",
        "Выполнил студент группы ББМО-01-23: Панков.Н.О\n",
        "\n",
        "Цель работы:\n",
        "\n",
        "1. Загрузить несколько моделей, обученных на датасете MNIST.\n",
        "2. Изучить теоретические основы атаки по переносу.\n",
        "3. Реализовать атаку FGSM на одну модель и проверить, как противоречивые примеры влияют на\n",
        "другую модель.\n",
        "4. Оценить точность обеих моделей на противоречивых примерах и проанализировать\n",
        "переносимость атак."
      ],
      "metadata": {
        "id": "-2WVZFtm_Sa_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "40rKED6E_IA8"
      },
      "outputs": [],
      "source": [
        "# Импорт всех необходимых библиотек\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка и подготовка данных\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "train_labels, test_labels = to_categorical(train_labels), to_categorical(test_labels)\n",
        "\n",
        "# Модель 1: Полносвязная нейронная сеть\n",
        "model1 = Sequential([Flatten(input_shape=(28, 28)), Dense(128, activation='relu'), Dense(10, activation='softmax')])\n",
        "model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model1.fit(train_images, train_labels, epochs=5)\n",
        "model1.save('mnist_model_1.h5')\n",
        "\n",
        "# Модель 2: Свёрточная нейронная сеть (CNN)\n",
        "model2 = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')])\n",
        "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model2.fit(train_images.reshape(-1, 28, 28, 1), train_labels, epochs=5)\n",
        "model2.save('mnist_model_2.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGKUjCp303j-",
        "outputId": "aede2cb6-9fdd-4717-fb22-3f8e462d3f9b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8775 - loss: 0.4322\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9645 - loss: 0.1247\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9746 - loss: 0.0814\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9822 - loss: 0.0597\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9860 - loss: 0.0451\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 23ms/step - accuracy: 0.9130 - loss: 0.2887\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 24ms/step - accuracy: 0.9837 - loss: 0.0532\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 23ms/step - accuracy: 0.9898 - loss: 0.0311\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 23ms/step - accuracy: 0.9940 - loss: 0.0193\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 23ms/step - accuracy: 0.9954 - loss: 0.0124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция FGSM атаки\n",
        "def fgsm_attack(image, epsilon, gradient):\n",
        "    return np.clip(image + epsilon * np.sign(gradient), 0, 1)\n",
        "\n",
        "# Генерация одного противоречивого примера\n",
        "def generate_adversarial_example(model, image, label, epsilon):\n",
        "    image = tf.convert_to_tensor(image.reshape((1, 28, 28, 1)))\n",
        "    label = tf.convert_to_tensor(np.argmax(label) if len(label.shape) > 1 else label)\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(image)\n",
        "        prediction = model(image)\n",
        "        loss = tf.keras.losses.categorical_crossentropy(label[None], prediction)\n",
        "    gradient = tape.gradient(loss, image)\n",
        "    return fgsm_attack(image.numpy(), epsilon, gradient.numpy()).reshape(28, 28)\n",
        "\n",
        "# Генерация множества противоречивых примеров\n",
        "def generate_adversarial_dataset(model, images, labels, epsilon):\n",
        "    return np.array([generate_adversarial_example(model, img, lbl, epsilon) for img, lbl in zip(images, labels)])\n",
        "\n",
        "# Генерация противоречивых примеров и отображение до/после\n",
        "epsilon = 0.1\n",
        "adversarial_images_model1 = generate_adversarial_dataset(model1, test_images, test_labels, epsilon)\n",
        "\n",
        "# Отображение оригинального и противоречивого изображения\n",
        "idx = 0\n",
        "plt.figure(figsize=(6, 3))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Original\")\n",
        "plt.imshow(test_images[idx], cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Adversarial\")\n",
        "plt.imshow(adversarial_images_model1[idx], cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "MhFR0i5O3CoQ",
        "outputId": "80fc0783-f26b-4e1c-9f61-f141a46e00ca"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Оценка моделей на противоречивых примерах\n",
        "acc1 = model1.evaluate(adversarial_images_model1, test_labels, verbose=0)[1]\n",
        "acc2 = model2.evaluate(adversarial_images_model1.reshape(-1, 28, 28, 1), test_labels, verbose=0)[1]\n",
        "\n",
        "print(f'Model1 Accuracy on Adversarial Examples: {acc1}')\n",
        "print(f'Model2 Accuracy on Transferred Adversarial Examples: {acc2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ur9LRze94oY3",
        "outputId": "e1153346-9ed6-43be-a131-6a18866999a3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model1 Accuracy on Adversarial Examples: 0.1216999962925911\n",
            "Model2 Accuracy on Transferred Adversarial Examples: 0.965499997138977\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Генерация и оценка противоречивых примеров от model2\n",
        "adversarial_images_model2 = generate_adversarial_dataset(model2, test_images.reshape(-1, 28, 28, 1), test_labels, epsilon)\n",
        "acc3 = model1.evaluate(adversarial_images_model2.reshape(-1, 28, 28), test_labels, verbose=0)[1]\n",
        "\n",
        "print(f'Model1 Accuracy on Adversarial Examples from Model2: {acc3}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9VbZSbZ5rP1",
        "outputId": "d5cd4e85-ce5b-4de7-cfdb-d33914d734c8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model1 Accuracy on Adversarial Examples from Model2: 0.9172000288963318\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вывод:\n",
        "\n",
        "В ходе работы было исследовано воздействие атаки по переносу, при которой противоречивые примеры, созданные для одной модели, использовались для атаки на другую. Метод FGSM позволил эффективно генерировать такие примеры, искажающие предсказания.\n",
        "\n",
        "Результаты эксперимента показали, что точность модели 1 резко упала до 12.17% на её собственных противоречивых примерах, что свидетельствует о высокой уязвимости к атакам. Однако модель 2, протестированная на тех же примерах, сохранила точность на уровне 96.55%, продемонстрировав значительную устойчивость к переносу атак.\n",
        "\n",
        "Когда противоречивые примеры были сгенерированы для модели 2 и использованы против модели 1, точность последней снизилась до 91.72%, что меньше, чем в первом случае, и подтверждает её меньшую восприимчивость к атакам, созданным для другой модели.\n",
        "\n",
        "Эти результаты показывают, что атака по переносу с использованием FGSM может существенно снизить точность, особенно если примеры созданы для целевой модели. В то же время, более устойчивые модели сохраняют точность при воздействии атак, перенесённых с других моделей, подчёркивая важность разработки методов защиты от таких атак."
      ],
      "metadata": {
        "id": "8MTYht016RaJ"
      }
    }
  ]
}